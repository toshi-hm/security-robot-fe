---
marp: true
theme: default
paginate: true
backgroundColor: #fff
---

# 強化学習を用いた警備ロボットの警備経路最適化

研究進捗報告

2025-11-01

---

## 目次

1. 研究概要
2. 研究の背景・目的
3. システムアーキテクチャ
4. 実装済み機能
5. 現在の進捗状況
6. 先行研究との比較
7. 今後の実施計画
8. まとめ

---

## 1. 研究概要

### 本研究の目的

**警備ロボットの巡回経路を強化学習により最適化する**

- セキュリティロボットが効率的な警備経路を自律的に学習
- リアルタイムの脅威情報に基づく動的な経路調整
- カバレッジ、探索、脅威対応のバランス最適化

---

## 2. 研究の背景・目的

### なぜこの研究が必要か？

**従来の課題**

- 固定的な巡回経路では変化する脅威に対応困難
- 人手による経路設定は時間とコストがかかる
- 環境の変化（侵入者、障害物）への適応が遅い

**強化学習による解決**

- 環境との相互作用を通じた自律学習
- 報酬関数による多目的最適化
- 動的環境への適応能力

---

## 3. システムアーキテクチャ

### 全体構成

**3層アーキテクチャ**

1. **フロントエンド**: Nuxt 4 + Vue 3 + TypeScript
2. **バックエンド**: FastAPI + Python 3.11
3. **強化学習エンジン**: Stable-Baselines3 + カスタムA3C実装

**通信方式**

- REST API（学習制御、モデル管理）
- WebSocket（リアルタイム進捗配信）
- Celery + Redis（バックグラウンドタスク管理）

---

## 4. 実装済み機能 - バックエンド

### ✅ 完全実装済み

- **データベース層**: SQLAlchemy ORM、TrainingJob/Metrics/EnvironmentStateモデル
- **API層**: 学習制御、ファイル管理、プレイバック、WebSocket API
- **強化学習統合**:
  - PPOアルゴリズム（Stable-Baselines3）
  - カスタムA3Cアルゴリズム実装
- **環境実装**: 標準環境 + 拡張環境（脅威レベル対応）
- **Celeryタスク**: 学習ジョブ管理、進捗通知、成果物アーカイブ
- **Docker環境**: API/PostgreSQL/Redis/Celeryの完全構成

---

## 4. 実装済み機能 - フロントエンド

### ✅ 完全実装済み

**テスト・品質**

- 総テスト数: **478テスト** (100%成功)
- カバレッジ: **98.11%** (目標85%を大幅超過)

**主要機能**

- ダッシュボード（セッション・モデル・プレイバック統計）
- 学習セッション管理（作成、開始、一時停止、再開、停止）
- リアルタイム可視化（進捗グラフ、環境マップ、ロボット位置）
- モデル管理（アップロード/ダウンロード、進捗バー）
- プレイバック機能（過去セッション再生）
- WebSocket統合（Native WebSocket + フォールバックポーリング）

---

## 5. 現在の進捗状況 - バックエンド

### 進捗サマリー（全9フェーズ）

| フェーズ | 内容               | 進捗率 | 状態 |
| -------- | ------------------ | ------ | ---- |
| Phase 1  | 環境準備・依存関係 | 100%   | ✅   |
| Phase 2  | データベースモデル | 100%   | ✅   |
| Phase 3  | Pydanticスキーマ   | 100%   | ✅   |
| Phase 4  | APIエンドポイント  | 97%    | 🔄   |
| Phase 5  | WebSocket通信      | 100%   | ✅   |
| Phase 6  | Celeryタスク       | 100%   | ✅   |
| Phase 7  | RL統合             | 100%   | ✅   |
| Phase 8  | テスト実装         | 80%    | 🔄   |
| Phase 9  | Docker環境         | 100%   | ✅   |

---

## 5. 現在の進捗状況 - フロントエンド

### 実装完了機能

**コアレイヤー**

- Domain層: 94.02%カバレッジ（TDD厳守）
- Repository層: 80.7%カバレッジ
- Composables層: 92.47%カバレッジ（依存性注入パターン）
- Components層: 73.68%カバレッジ（19/19コンポーネント）
- Pages層: 100%カバレッジ（11/11ページ）
- Stores層: 100%カバレッジ（Pinia統合）

**UI拡張機能**

- インタラクティブ環境マップ（ズーム/パン/リセット）
- 4種類のリアルタイムチャート（報酬、損失、カバレッジ、探索）
- 完全日本語化（19個のパラメータツールチップ）

---

## 5. 実装の特徴

### 強化学習アルゴリズム

**PPO (Proximal Policy Optimization)**

- Stable-Baselines3ベース
- 安定した学習性能
- ハイパーパラメータ調整可能

**A3C (Asynchronous Advantage Actor-Critic)**

- カスタム実装
- マルチワーカー並列学習
- GAE（Generalized Advantage Estimation）による価値推定

---

## 5. 報酬設計

### 多目的最適化

```python
報酬 = α × カバレッジ報酬
     + β × 探索報酬
     + γ × 脅威対応報酬
```

**カバレッジ報酬**: 未訪問エリアの探索を促進
**探索報酬**: 新しい行動パターンの発見を奨励
**脅威対応報酬**: 高脅威エリアの優先的巡回

**重みパラメータ（α, β, γ）は学習時に調整可能**

---

## 6. 先行研究など

### 最新研究動向（2024年）

**学術論文からの知見**

1. **[都市警備経路計画](https://www.jstage.jst.go.jp/article/sicejl/57/6/57_454/_pdf)** (MDPI 2024-2025)
   - ST-GCN（時空間グラフ畳み込みネットワーク）で犯罪リスク予測
   - DDQNがDQNより高速収束、PPOはセンサーノイズに強い

2. **海上無人警備船** (IJRR 2024)
   - DDPG改良版で経路計画
   - 報酬関数の疎性問題を解決

3. **サイバー攻撃経路最適化** (SpringerOpen 2024)
   - PKPPO（事前知識ベースPPO）で攻撃経路を二目的最適化

---

## 6. 本研究の特徴・差別化

### 先行研究との比較優位性

**1. 統合開発環境**

- フロントエンド/バックエンド/RL統合の完全実装
- リアルタイムWebSocket可視化
- モデル管理・プレイバック機能

**2. 複数アルゴリズム対応**

- PPO（安定性重視）とA3C（並列学習）の切替可能
- 環境に応じたアルゴリズム選択

**3. 実用指向の設計**

- Docker完全対応、スケーラブルアーキテクチャ
- API駆動設計でフロントエンド統合容易
- 成果物自動アーカイブ、プレイバック録画機能

---

## 7. 今後の実施計画

### 短期計画（1-2ヶ月）

APIエンドポイント最終調整（97% → 100%）

- 環境セッション操作APIのドキュメント完備
- エラーハンドリング強化

テスト実装（80% → 100%）

- Celery統合テスト
- 負荷テスト、パフォーマンステスト
- カバレッジ70%以上達成

**検証**

- 学習エンドツーエンド検証
- GPU環境での学習性能評価

---

## 7. 中期計画（3-6ヶ月）

### 学習性能の向上

**1. ハイパーパラメータチューニング**

- 学習率、バッチサイズ、エポック数の最適化
- 報酬重み（α, β, γ）の実験的評価

**2. 環境の複雑化**

- 動的障害物の導入
- 複数ロボットの協調学習
- より複雑な脅威パターン

**3. 新規アルゴリズムの検討**

- DQN、DDQNの実装比較
- Transformerベースの政策ネットワーク検討

---

## 7. 長期計画

### 実用化への展開

**1. シミュレーション環境の高度化**

- 3D環境への拡張
- 物理シミュレーション統合（PyBullet, MuJoCo）

**2. 実機ロボットへの展開(間に合わない)**

- ROS(Robot Operating System)との統合
- 実環境でのセンサーデータ統合

---

## 8. まとめ

### 現在の達成状況

**✅ 実装完了**

- バックエンドAPI基盤（97%完成）
- フロントエンドUI（100%完成、478テスト通過）
- PPO/A3C強化学習エンジン
- Docker環境構築
- WebSocketリアルタイム可視化

**🔄 進行中**

- APIエンドポイント最終調整（3%残）
- テスト実装拡充（20%残）
- 実機検証準備

---

## 8. まとめ（続き）

### 研究の意義

**技術的貢献**

- 警備ロボット向け強化学習システムの包括的実装
- PPO/A3C複数アルゴリズムの比較検証基盤
- リアルタイム可視化による学習過程の理解促進

**実用的価値**

- API駆動設計による拡張性
- Docker対応による展開容易性
- モデル管理・プレイバック機能による運用支援

**今後の展望**

- 実機ロボットへの展開
- より複雑な環境・タスクへの適用
- 学会発表・論文化

---

## ご清聴ありがとうございました

### 質疑応答

**プロジェクトリポジトリ**

- フロントエンド: `security-robot-fe/`
- バックエンド: `security-robot-be/`
